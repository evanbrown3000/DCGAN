{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dogs!\n",
    "Uses GAN, customized variant of: <br>\n",
    "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "(Alec Radford, Luke Metz, Soumith Chintala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other variants to try:\n",
    "#-add label info to encoder input \n",
    "#-try variational GAN\n",
    "#possibly more augments: tf.image.random_crop, tf.image.crop_central,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import PIL\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2DTranspose, Conv2D, BatchNormalization, ReLU, LeakyReLU, Dropout, Dense, Activation, Input, Reshape, Flatten\n",
    "import keras\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "noise_dim = 120\n",
    "num_examples_to_generate = 16\n",
    "output_activation = 'tanh'\n",
    "load_checkpoint = False\n",
    "data_dir='/home/evan/Datasets/tensorflow'\n",
    "buffer_size = 3200\n",
    "batch_size = 32\n",
    "image_size = (64,64)\n",
    "channels = 3\n",
    "latent_size = 120 #i.e. size of generator input\n",
    "filters_gen = 64 #filters in second to last generator conv layer \n",
    "filters_dis = 64 #filters in first discriminator conv layer\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "if output_activation == 'sigmoid':\n",
    "    def normalize(x):\n",
    "        return x / 255. #0 to 1 \n",
    "    def denormalize(x):\n",
    "        return x * 255.\n",
    "if output_activation == 'tanh':\n",
    "    def normalize(x):\n",
    "        return (x - 127.5) / 127.5  #-1 to 1 \n",
    "    def denormalize(x):\n",
    "        return (x * 127.5) + 127.5 \n",
    "\n",
    "try:\n",
    "    train_dataset = tfds.load('stanford_dogs', as_supervised=False, split='train', data_dir=data_dir, download=False)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    train_dataset = tfds.load('stanford_dogs', as_supervised=False, split='train', data_dir=data_dir, download=True)\n",
    "\n",
    "def transform(x):\n",
    "    x = x['image']\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = tf.image.resize(x, image_size, method='gaussian')\n",
    "    x = normalize(x)\n",
    "    x = tf.image.random_flip_left_right(x) \n",
    "    x = tf.image.random_brightness(x, .05)\n",
    "    return x\n",
    "\n",
    "# Lanczos kernel with radius 5. Very-high-quality filter but may have stronger ringing\n",
    "train_dataset = train_dataset.map(lambda x: transform(x))\\\n",
    "                             .shuffle(buffer_size)\\\n",
    "                             .batch(batch_size)\\\n",
    "                             .prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((next(train_dataset.as_numpy_iterator())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = tf.random_normal_initializer(stddev=0.02)\n",
    "gamma_init = tf.random_normal_initializer(1., 0.02)\n",
    "\n",
    "def make_generator_model():\n",
    "    model = keras.Sequential([\n",
    "            # input is Z, going into a convolution\n",
    "            Input((latent_size)),\n",
    "            Dense(np.prod([image_size[0]/16, image_size[1]/16, 3]), kernel_initializer=w_init),\n",
    "            Reshape((image_size[0]//16,image_size[0]//16)+(3,)),\n",
    "            Conv2DTranspose(filters = filters_gen * 8, kernel_size=5, strides=2,\n",
    "                            padding='same',use_bias=False, kernel_initializer=w_init),\n",
    "            BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "            ReLU(),\n",
    "            Conv2DTranspose(filters = filters_gen * 4, kernel_size=5, strides=2,\n",
    "                            padding='same',use_bias=False, kernel_initializer=w_init),\n",
    "            BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "            ReLU(),\n",
    "            Conv2DTranspose(filters = filters_gen * 2, kernel_size=5, strides=2,\n",
    "                            padding='same',use_bias=False, kernel_initializer=w_init),\n",
    "            BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "            ReLU(),\n",
    "            Conv2DTranspose(filters = filters_gen, kernel_size=5, strides=2,\n",
    "                            padding='same',use_bias=False, kernel_initializer=w_init),\n",
    "            BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "            ReLU(),\n",
    "            Conv2DTranspose(channels, 4, 1,padding='same',use_bias=False),\n",
    "            Activation(output_activation)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "generator.summary()\n",
    "noise = tf.random.normal([1, latent_size])\n",
    "generated_image = generator(noise, training=False).numpy()\n",
    "print(generated_image.shape)\n",
    "print(generated_image.sum())\n",
    "plt.imshow(generated_image[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(filters_dis,kernel_size=5, strides=2, padding='same',\n",
    "               use_bias=False, input_shape=image_size+(3,),\n",
    "               kernel_initializer=w_init),\n",
    "        BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(filters_dis*2,kernel_size=5, strides=2, padding='same',\n",
    "               use_bias=False, kernel_initializer=w_init),\n",
    "        BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(filters_dis*4,kernel_size=5, strides=2, padding='same',\n",
    "               use_bias=False,kernel_initializer=w_init),\n",
    "        BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(filters_dis*8,kernel_size=5, strides=2, padding='same',\n",
    "               use_bias=False, kernel_initializer=w_init),\n",
    "        BatchNormalization(axis=-1,gamma_initializer=gamma_init, momentum=0.9),\n",
    "        LeakyReLU(0.2),\n",
    "        Flatten(),\n",
    "        Dense(1),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "discriminator.summary()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(lr, beta1)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(lr, beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints' + datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_checkpoint:\n",
    "    ckpt = tf.train.Checkpoint(\n",
    "        generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, generator=generator, discriminator=discriminator\n",
    "    )\n",
    "    manager = tf.train.CheckpointManager(ckpt, './training_checkpoints/', max_to_keep=3)\n",
    "    ckpt.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inferechannelse mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, :])\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ef37928cbe5219b2fcf8404ea29b31b1a966345f86328e41ae7ac18a87552f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tensorflow': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
